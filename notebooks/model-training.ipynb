{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "vipoooool_new_plant_diseases_dataset_path = kagglehub.dataset_download('vipoooool/new-plant-diseases-dataset')\n",
    "\n",
    "print('Data source import complete.')\n",
    "\n",
    "\n",
    "%pip install colorama\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import colorama\n",
    "from colorama import Fore, Style\n",
    "\n",
    "Root_dir = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = Root_dir + \"/train\"\n",
    "valid_dir = Root_dir + \"/valid\"\n",
    "test_dir = \"/kaggle/input/new-plant-diseases-dataset/test\"\n",
    "Diseases_classes = os.listdir(train_dir)\n",
    "\n",
    "print(Fore.GREEN +str(Diseases_classes))\n",
    "print(\"\\nTotal number of classes are: \", len(Diseases_classes))\n",
    "\n",
    "plt.figure(figsize=(60,60), dpi=200)\n",
    "cnt = 0\n",
    "plant_names = []\n",
    "tot_images = 0\n",
    "\n",
    "for i in Diseases_classes:\n",
    "    cnt += 1\n",
    "    plant_names.append(i)\n",
    "    plt.subplot(7,7,cnt)\n",
    "\n",
    "    image_path = os.listdir(train_dir + \"/\" + i)\n",
    "    print(Fore.GREEN)\n",
    "    print(\"The Number of Images in \" +i+ \":\", len(image_path), end= \" \")\n",
    "    tot_images += len(image_path)\n",
    "\n",
    "    img_show = plt.imread(train_dir + \"/\" + i + \"/\" + image_path[0])\n",
    "\n",
    "    plt.imshow(img_show)\n",
    "    plt.xlabel(i,fontsize=30)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "print(\"\\nTotal Number of Images in Directory: \", tot_images)\n",
    "\n",
    "plant_names = []\n",
    "Len = []\n",
    "for i in Diseases_classes:\n",
    "    plant_names.append(i)\n",
    "    imgs_path = os.listdir(train_dir + \"/\" + i)\n",
    "    Len.append(len(imgs_path))\n",
    "\n",
    "Len.sort(reverse=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "plt.figure(figsize=(20,20),dpi=200)\n",
    "ax = sns.barplot(x= Len, y= plant_names, palette=\"Greens\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
    "valid = ImageFolder(valid_dir, transform=transforms.ToTensor())\n",
    "\n",
    "train\n",
    "\n",
    "train[0]\n",
    "\n",
    "train[7000]\n",
    "\n",
    "train[70000]\n",
    "\n",
    "img, label = train[0]\n",
    "print(img.shape, label)\n",
    "\n",
    "def show_image(image, label):\n",
    "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "\n",
    "\n",
    "image_list = [0, 3000, 5000, 8000, 12000, 15000, 60000, 70000]\n",
    "\n",
    "chs = 0\n",
    "for img in image_list:\n",
    "    chs += 1\n",
    "    plt.subplot(2,4,chs)\n",
    "    print(Fore.GREEN)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(img,fontsize=10)\n",
    "    plt.title(train[img][1])\n",
    "    show_image(*train[img])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)\n",
    "\n",
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dataloader:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dataloader)\n",
    "\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Moving data into GPU, WrappedDataLoader\n",
    "train_dataloader = DeviceDataLoader(train_dataloader, device)\n",
    "valid_dataloader = DeviceDataLoader(valid_dataloader, device)\n",
    "\n",
    "# for calculating the accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# resnet architecture\n",
    "class CNN_NeuralNet(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "\n",
    "        self.conv3 = ConvBlock(128, 256, pool=True)\n",
    "        self.conv4 = ConvBlock(256, 512, pool=True)\n",
    "        #self.conv5 = ConvBlock(256, 256, pool=True)\n",
    "        #self.conv6 = ConvBlock(256, 512, pool=True)\n",
    "        #self.conv7 = ConvBlock(512, 512, pool=True)\n",
    "\n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "\n",
    "    def forward(self, x): # x is the loaded batch\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        #out = self.conv5(out)\n",
    "        #out = self.conv6(out)\n",
    "        #out = self.conv7(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "# defining the model and moving it to the GPU\n",
    "# 3 is number of channels RGB, len(train.classes()) is number of diseases.\n",
    "model = to_device(CNN_NeuralNet(3, len(train.classes)), device)\n",
    "model\n",
    "\n",
    "# for training\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n",
    "                grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []  #For collecting the results\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # scheduler for one cycle learniing rate\n",
    "    #Sets the learning rate of each parameter group according to the 1cycle learning rate policy.\n",
    "    #The 1cycle policy anneals the learning rate from an initial learning rate to some\n",
    "    #maximum learning rate and then from that maximum learning rate to some minimum learning rate\n",
    "    #much lower than the initial learning rate.\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr,\n",
    "                                                epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient clipping\n",
    "            #Clip the gradients of an iterable of parameters at specified value.\n",
    "            #All from pytorch documantation.\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # recording and updating learning rates\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "             # validation\n",
    "\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "%%time\n",
    "history = [evaluate(model, valid_dataloader)]\n",
    "history\n",
    "\n",
    "num_epoch = 5\n",
    "lr_rate = 0.01\n",
    "grad_clip = 0.15\n",
    "weight_decay = 1e-4\n",
    "optims = torch.optim.Adam\n",
    "\n",
    "%%time\n",
    "history += fit_OneCycle(num_epoch, lr_rate, model, train_dataloader, valid_dataloader,\n",
    "                             grad_clip=grad_clip,\n",
    "                             weight_decay=weight_decay,\n",
    "                             opt_func=optims)\n",
    "\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "\n",
    "for i in history:\n",
    "    val_acc.append(i['val_acc'])\n",
    "    val_loss.append(i['val_loss'])\n",
    "    train_loss.append(i.get('train_loss'))\n",
    "\n",
    "epoch_count = range(1,7)\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plt.plot(epoch_count, train_loss, 'r--', color= 'orangered')\n",
    "plt.plot(epoch_count, val_loss, '--bo',color= 'green', linewidth = '2.5', label='line with marker')\n",
    "plt.legend(['Training Loss', 'Val Loss'])\n",
    "plt.title('Number of epochs & Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(np.arange(1,7,1))\n",
    "plt.show();\n",
    "\n",
    "epoch_count = range(1,7)\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plt.plot(epoch_count, val_acc, '--bo',color= 'green', linewidth = '2.5', label='line with marker')\n",
    "plt.legend(['Val Acc'])\n",
    "plt.title('Number of epochs & Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.xticks(np.arange(1,7,1))\n",
    "plt.show();\n",
    "\n",
    "\n",
    "<div style = 'border : 3px solid non; background-color:#ECFFDC ; ;padding:10px'>\n",
    "\n",
    "\n",
    "**Use Model for Test Dataset:**\n",
    "\n",
    "\n",
    "   - Now it's time to test the model on the **test_dir**.\n",
    "\n",
    "test = ImageFolder(test_dir, transform=transforms.ToTensor())\n",
    "test_images = sorted(os.listdir(test_dir + '/test'))\n",
    "print(Fore.GREEN)\n",
    "print(test_images)\n",
    "print(len(test_images))\n",
    "\n",
    "def predict_image(img, model):\n",
    "    \"\"\"Converts image to array and return the predicted class\n",
    "        with highest probability\"\"\"\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "\n",
    "    return train.classes[preds[0].item()]\n",
    "\n",
    "<div style = 'border : 3px solid non; background-color:#ECFFDC ; ;padding:10px'>\n",
    "\n",
    "\n",
    "**Final Prediction:**\n",
    "\n",
    "\n",
    "   - Let's see how the model works.\n",
    "\n",
    "# predicting first image\n",
    "img, label = test[1]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print(Fore.GREEN)\n",
    "print('Label:', test_images[1], ', Predicted:', predict_image(img, model))\n",
    "\n",
    "# predicting first image\n",
    "img, label = test[5]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print(Fore.GREEN)\n",
    "print('Label:', test_images[5], ', Predicted:', predict_image(img, model))\n",
    "\n",
    "# predicting first image\n",
    "img, label = test[9]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print(Fore.GREEN)\n",
    "print('Label:', test_images[9], ', Predicted:', predict_image(img, model))\n",
    "\n",
    "# predicting first image\n",
    "img, label = test[16]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print(Fore.GREEN)\n",
    "print('Label:', test_images[16], ', Predicted:', predict_image(img, model))\n",
    "\n",
    "# predicting first image\n",
    "img, label = test[26]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print(Fore.GREEN)\n",
    "print('Label:', test_images[26], ', Predicted:', predict_image(img, model))\n",
    "\n",
    "# getting all predictions (actual label vs predicted)\n",
    "for i, (img, label) in enumerate(test):\n",
    "    print(Fore.GREEN)\n",
    "    print('Label:', test_images[i], ', Predicted:', predict_image(img, model))\n",
    "\n",
    "import torch\n",
    "\n",
    "# Define the path to save the model\n",
    "model_save_path = 'plant_disease_model.pth'\n",
    "\n",
    "# Save the entire model\n",
    "torch.save(model, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "Saving the model's state dictionary to an h5 file is a way to store the learned parameters of the model in a more universal format. You can then load these parameters into a compatible model architecture in PyTorch or potentially other frameworks.\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "# Define the path to save the h5 file\n",
    "model_save_path = 'plant_disease_model_state_dict.h5'\n",
    "\n",
    "# Save the model's state dictionary\n",
    "with h5py.File(model_save_path, 'w') as f:\n",
    "    for name, param in model.state_dict().items():\n",
    "        f.create_dataset(name, data=param.cpu().numpy())\n",
    "\n",
    "print(f\"Model state dictionary saved to {model_save_path}\")\n",
    "\n",
    "from torchvision import datasets\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "# ✅ Step 1: Set your training folder path\n",
    "# This should be the same folder you used in training\n",
    "# In your case, it looks like:\n",
    "data_dir = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
    "\n",
    "# ✅ Step 2: Load dataset to get class names\n",
    "dataset = datasets.ImageFolder(data_dir)\n",
    "classes = dataset.classes\n",
    "\n",
    "# ✅ Step 3: Save classes to JSON\n",
    "with open(\"classes.json\", \"w\") as f:\n",
    "    json.dump(classes, f)\n",
    "\n",
    "print(\"Total Classes:\", len(classes))\n",
    "print(\"Sample Classes:\", classes[:5])  # Show first 5 classes for reference\n",
    "\n",
    "# ✅ Step 4: Download the classes.json file\n",
    "files.download(\"classes.json\")\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "# Define the path to the saved h5 file\n",
    "model_save_path = 'plant_disease_model_state_dict.h5'\n",
    "\n",
    "# Load the model's state dictionary\n",
    "loaded_state_dict = {}\n",
    "with h5py.File(model_save_path, 'r') as f:\n",
    "    for name, param in f.items():\n",
    "        loaded_state_dict[name] = torch.from_numpy(param[:])\n",
    "\n",
    "# Create a new instance of the model architecture\n",
    "# You need to ensure the architecture matches the saved state dictionary\n",
    "# Based on your previous code, the architecture is CNN_NeuralNet\n",
    "# You might need to define or import CNN_NeuralNet if it's not in the current scope\n",
    "# You also need to know the input channels (3 for RGB) and the number of diseases (38)\n",
    "# These values were used when defining the model earlier\n",
    "loaded_model = CNN_NeuralNet(3, len(Diseases_classes)) # Assuming CNN_NeuralNet is defined and Diseases_classes is available\n",
    "\n",
    "# Load the state dictionary into the new model instance\n",
    "loaded_model.load_state_dict(loaded_state_dict)\n",
    "\n",
    "# Move the loaded model to the appropriate device\n",
    "loaded_model = to_device(loaded_model, device) # Assuming to_device and device are defined\n",
    "\n",
    "print(f\"Model state dictionary loaded from {model_save_path}\")\n",
    "\n",
    "<div style = 'border : 3px solid non; background-color:#ECFFDC ; ;padding:10px'>\n",
    "\n",
    "\n",
    "   - Everything is good and the model predict well the test dataset.\n",
    "    \n",
    "   - **Happy Learning Guys**\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#2E8B57 ;margin:0;color:#ffffff;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">Warm Wishes</p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
